---
title: "EDUC152, Problem Set #3"
# author: "INSERT YOUR NAME HERE"
date: ""
urlcolor: blue
output: 
  #pdf_document:
    #pandoc_args: ["--extract-media", "."]
    #keep_md: yes
    #self_contained: true
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    self_contained: true
    #theme: default
    #highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", highlight = TRUE, warning = FALSE, message = FALSE)

# remove scientific notation
options(scipen=999)
```

<span style="color:red"><b>Grade: /50<b></span>

# Overview

## Tips on notation

<details><summary><b>Click here for [Tips of notation]</b></summary>

<br>

Some questions will ask you to write out notation and/or equations.

You can write out notation/equations one of two ways: (1) using "inline equations," which begin with a dollar sign \$ and end with a dollar sign \$; *OR* (2) you can write out notation/equation in plain text without. We encourage you to try inline equations, but fine if you do not.

Tips on writing notation/equations using "inline equations':

- Make sure there are no spaces after the dollar sign \$ that begins the equation and no spaces before the dollar sign that ends the equation. 
  - For example, you would write out the notation for treated potential outcome like this: $Y_i(1)$
  - But this wouldn't work: $ Y_i(1)$
  - And this wouldn't work: $Y_i(1) $
- Special characters -- like greek letters -- within inline equations are referred to using special symbols that start with a backslash
  - e.g., "Beta" is `\beta`: $\beta$
  - "Mu" (symbol for population mean) is `\mu`: $\mu$
- Subscripts after a character or symbol are specified like this:
  - e.g., "Beta subscript 1" is `beta_1`: $\beta_1$
  - e.g., "Mu subscript Y" (referring to population mean of variable Y) is `\mu_Y`: $\mu_Y$
- "hats" are specified by wrapping the character/symbol within curly brackets `\hat{}` like this:
  - e.g., "Beta hat" is `\hat{\beta}`: $\hat{\beta}$
  - e.g., "Beta hat subscript 1" is `\hat{\beta}_1` (note that the subscript is not within the "hat"): $\hat{\beta}_1$
- "bars" are specified by wrapping the character/symbol within curly brackets `\bar{}` like this:
  - e.g., "sample mean of Y" is `\bar{Y}`: $\bar{Y}$
- Don't worry about getting it perfect and don't spend too much time trying to get it perfect; if you are trying, that is a great start! and fine to use inline equations for some notation/equations and plain text for others that you can't figure out.  

<br>

Tips on writing notation/equations in plain text

- Instead of writing $Y_i(1)$, you could write this: Y_i(1)
- Instead of writing $Y_i = \beta_0 + \beta_1X_i + u_i$, you could write this: Y_i = beta_0 + beta_1*X_i + u_i
- Instead of writing $\hat{Y_i} = \hat{\beta}_0 + \hat{\beta}_1X_i$, you could write something like this: Y_hat_i = beta_hat_0 + beta_hat_1*X_i
- don't worry if it doesn't look pretty!

</details>

## Load libraries and data

Please run the code in the following chunk, which does the following:

- Loads libraries
- Loads and creates data frame from IPEDS/College Scorecard Masters degrees in Education 


_Note: code chunk omitted from html document using include = FALSE_

```{r, include=FALSE}
#-----------------------------------------------------------------------------
# Load libraries
#-----------------------------------------------------------------------------

  #install.packages('tidyverse') # if you haven't installed already
  #install.packages('labelled') # if you haven't installed already
  #install.packages('patchwork') # if you haven't installed already

library(tidyverse) # load tidyverse package
library(labelled) # load labelled package package
library(patchwork)

##########
########## RUN SCRIPT THAT CREATES USER DEFINED FUNCTIONS
##########

source(file = url('https://github.com/anyone-can-cook/educ152/raw/main/scripts/user_defined_functions/create_inference_functions.R'))


##########
########## IPEDS
##########

# Load ipeds dataset from course website url
load(file = url('https://github.com/anyone-can-cook/educ152/raw/main/data/ipeds/output_data/panel_data.RData'))

# Create ipeds data frame with fewer variables/observations
df_ipeds_pop <- panel_data %>%
  # keep IPEDS tuition data from fall of which year (e.g., fall 2016 is price for programs in 2016-17 academic year)
  filter(year == 2016) %>%
  # which universities to keep:
    # 2015 carnegie classification: keep research universities (15,16,17) and master's universities (18,19,20)
  filter(c15basic %in% c(15,16,17,18,19,20)) %>%
  # which variables to keep
  select(instnm,unitid,opeid6,opeid,control,c15basic,stabbr,city,zip,locale,obereg, # basic institutional characteristics
         tuition6,fee6,tuition7,fee7, # avg tuition and fees for full-time grad, in-state and out-of-state
         isprof3,ispfee3,osprof3,ospfee3, # avg tuition and fees for MD, in-state and out-of-state
         isprof9,ispfee9,osprof9,ospfee9, # avg tuition and fees for Law, in-state and out-of-state
         chg4ay3,chg7ay3,chg8ay3) %>% # [undergraduate] books+supplies; off-campus (not with family) room and board; off-campus (not with family) other expenses
  # rename variables; syntax <new_name> = <old_name>
  rename(region = obereg, # revion
         tuit_grad_res = tuition6, fee_grad_res = fee6, tuit_grad_nres = tuition7, fee_grad_nres = fee7, # grad
         tuit_md_res = isprof3, fee_md_res = ispfee3, tuit_md_nres = osprof3, fee_md_nres = ospfee3, # md
         tuit_law_res = isprof9, fee_law_res = ispfee9, tuit_law_nres = osprof9, fee_law_nres = ospfee9, # law
         books_supplies = chg4ay3, roomboard_off = chg7ay3, oth_expense_off = chg8ay3) %>% # [undergraduate] expenses
  # create measures of tuition+fees
  mutate(
    tuitfee_grad_res = tuit_grad_res + fee_grad_res, # graduate, state resident
    tuitfee_grad_nres = tuit_grad_nres + fee_grad_nres, # graduate, non-resident
    tuitfee_md_res = tuit_md_res + fee_md_res, # MD, state resident
    tuitfee_md_nres = tuit_md_nres + fee_md_nres, # MD, non-resident
    tuitfee_law_res = tuit_law_res + fee_law_res, # Law, state resident
    tuitfee_law_nres = tuit_law_nres + fee_law_nres) %>% # Law, non-resident  
  # create measures of cost-of-attendance (COA) as the sum of tuition, fees, book, living expenses
  mutate(
    coa_grad_res = tuit_grad_res + fee_grad_res + books_supplies + roomboard_off + oth_expense_off, # graduate, state resident
    coa_grad_nres = tuit_grad_nres + fee_grad_nres + books_supplies + roomboard_off + oth_expense_off, # graduate, non-resident
    coa_md_res = tuit_md_res + fee_md_res + books_supplies + roomboard_off + oth_expense_off, # MD, state resident
    coa_md_nres = tuit_md_nres + fee_md_nres + books_supplies + roomboard_off + oth_expense_off, # MD, non-resident
    coa_law_res = tuit_law_res + fee_law_res + books_supplies + roomboard_off + oth_expense_off, # Law, state resident
    coa_law_nres = tuit_law_nres + fee_law_nres + books_supplies + roomboard_off + oth_expense_off) # %>% # Law, non-resident    
  # [COMMENTED THIS OUT] keep only observations that have non-missing values for the variable coa_grad_res
    # this does cause us to lose some interesting universities, but doing this will eliminate some needless complications with respect to learning core concepts about statistical inference
  #filter(!is.na(coa_grad_res))

# Add variable labels to the tuit+fees variables and coa variables
  # tuition + fees variables
    var_label(df_ipeds_pop[['tuitfee_grad_res']]) <- 'graduate, full-time, resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_grad_nres']]) <- 'graduate, full-time, non-resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_md_res']]) <- 'MD, full-time, state resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_md_nres']]) <- 'MD, full-time, non-resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_law_res']]) <- 'Law, full-time, state resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_law_nres']]) <- 'Law, full-time, non-resident; avg tuition + required fees'
    
  # COA variables
    var_label(df_ipeds_pop[['coa_grad_res']]) <- 'graduate, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_grad_nres']]) <- 'graduate, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_md_res']]) <- 'MD, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_md_nres']]) <- 'MD, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_law_res']]) <- 'Law, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_law_nres']]) <- 'Law, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'

  #df_ipeds_pop %>% glimpse()

rm(panel_data) # comment this line out if you want to keep data frame panel_data

##########
########## SCORECARD DATA ON DEBT AND EARNINGS
##########

# load scorecard dataset from course website url

load(file = url('https://github.com/anyone-can-cook/educ152/raw/main/data/college_scorecard/output_data/df_debt_earn_panel_labelled.RData'))

df_scorecard <- df_debt_earn_panel_labelled %>%
    # keep most recent year of data
    filter(field_ay == '2017-18') %>%
    # keep master's degrees
    filter(credlev == 5) %>%
    # carnegie categories to keep: 15 = Doctoral Universities: Very High Research Activity; 16 = Doctoral Universities: High Research Activity
      # note: variable ccbasic from scorecard data is 2015 carnegie classification
    filter(ccbasic %in% c(15,16,17,18,19,20)) %>%
    # drop "parent plus" loan variables and other vars we won't use in this lecture
    select(-contains('_pp'),-contains('_any'),-field_ay,-st_fips,-zip,-longitude,-latitude,-locale2,-highdeg,-accredagency,-relaffil,-hbcu,-annhi,-tribal,-aanapii,-hsi,-nanti,-main,-numbranch,-control) %>%
    # create variable for broad field of degree (e.g., education, business)
    mutate(cipdig2 = str_sub(string = cipcode, start = 1, end = 2)) %>%
    # shorten variable cipdesc to make it more suitable for printing
    mutate(cipdesc = str_sub(string = cipdesc, start = 1, end = 50)) %>%
    # re-order variables
    relocate(opeid6,unitid,instnm,ccbasic,stabbr,city,cipdig2)

  #df_scorecard %>% glimpse()

# For debt and earnings variables, convert from character to numeric variables (which replaces "PrivacySuppressed" values with NA values)
df_scorecard <- df_scorecard %>%
  mutate(
    debt_all_stgp_eval_n = as.numeric(debt_all_stgp_eval_n),
    debt_all_stgp_eval_mean = as.numeric(debt_all_stgp_eval_mean),
    debt_all_stgp_eval_mdn = as.numeric(debt_all_stgp_eval_mdn),
    debt_all_stgp_eval_mdn10yrpay = as.numeric(debt_all_stgp_eval_mdn10yrpay),
    earn_count_wne_hi_1yr = as.numeric(earn_count_wne_hi_1yr),
    earn_mdn_hi_1yr = as.numeric(earn_mdn_hi_1yr),
    earn_count_wne_hi_2yr = as.numeric(earn_count_wne_hi_2yr),
    earn_mdn_hi_2yr = as.numeric(earn_mdn_hi_2yr)
  ) 

# add variable label to variable cipdig2
  attr(df_scorecard[['cipdig2']], which = 'label') <- 'broad degree field code = 2-digit classification of instructional programs (CIP) degree code'

# add variable label attribute back to debt and earnings variables
  for(v in c('debt_all_stgp_eval_n','debt_all_stgp_eval_mean','debt_all_stgp_eval_mdn','debt_all_stgp_eval_mdn10yrpay','earn_count_wne_hi_1yr','earn_mdn_hi_1yr','earn_count_wne_hi_2yr','earn_mdn_hi_2yr','cipdesc')) {
    
    #writeLines(str_c('object v=', v))
    #writeLines(attr(df_debt_earn_panel_labelled[[v]], which = 'label'))
    
    attr(df_scorecard[[v]], which = 'label') <- attr(df_debt_earn_panel_labelled[[v]], which = 'label')
  }

#df_scorecard %>% glimpse()

rm(df_debt_earn_panel_labelled) # comment this line out if you want to keep data frame df_debt_earn_panel_labelled
#earn_mdn_hi_2yr

##########
########## LEFT JOIN SCORECARD AND IPEDS DATA
##########

# investigate data structure

  # df_scorecard; these vars uniquely identify observations
    df_scorecard %>% group_by(opeid6,cipcode) %>% summarise(n_per_key=n()) %>% ungroup() %>% count(n_per_key)

  # df_ipeds_pop: these vars uniquely identify observations
    df_ipeds_pop %>% group_by(unitid) %>% summarise(n_per_key=n()) %>% ungroup() %>% count(n_per_key)
    
# join
  # start with df_ipeds_pop, keep selected variables; then do do a right_join (i.e., keep obs in y table)
    
  df_score_ipeds <- df_ipeds_pop %>% 
    select(-instnm,-opeid6,-opeid,-c15basic,-region,-locale,-city,-stabbr,-zip) %>% mutate(one=1) %>%
    right_join(y=df_scorecard, by = 'unitid')
     #df_score_ipeds %>% glimpse()
  
  # 52 unitids from scorecard that don't have a match in ipeds
    # could be due to differences in year; decision: drop thiese
    df_score_ipeds %>% filter(is.na(one)) %>% count(unitid) # 52 unitids from scorecard data with missing IPEDS data
    df_score_ipeds %>% filter(is.na(one)) %>% count(instnm) # 52 unitids from scorecard data with missing IPEDS data
  

  df_score_ipeds <- df_score_ipeds %>% 
    # drop unitids from scorecard that don't merge to ipeds data (on tuition)
    filter(!is.na(one)) %>% 
    # drop observations that don't have mean debt data
    filter(!is.na(debt_all_stgp_eval_mean)) %>% 
    # drop for-profits
    filter(control !=3) %>%
    # drop tuition/coa vars for law and md
    select(-one,-contains('law'),-contains('md_')) %>%
    relocate(opeid6,unitid,instnm,control,ccbasic,stabbr,region,city,locale,cipdig2,cipcode,cipdesc,credlev,creddesc,
      contains('ipeds'),starts_with('debt'),starts_with('earn'))
    
  df_score_ipeds %>% glimpse()

rm(df_ipeds_pop) # comment this line out if you want to keep ipeds data frame
rm(df_scorecard) # comment this line out if you want to keep scorecard data frame

# Investigate analysis data frame `df_score_ipeds`  

  # data structure: variables that uniquely identify obs
    df_score_ipeds %>% group_by(opeid6,cipcode) %>% summarise(n_per_key=n()) %>% ungroup() %>% count(n_per_key)
  
  ##### create data frame that only contains observations for MAs in education
  
  #particularly the degree "Education General", which is associated with general Education programs
    
df_score_ipeds %>% filter(cipdig2=="13") %>% count(cipcode)
df_score_ipeds %>% filter(cipdig2=="13") %>% count(cipdesc)

  df_edu <- df_score_ipeds %>% 
    filter(cipcode=='1301') %>%
    # remove observations with missing values of cost of attendance (better for teaching concepts)
    filter(!is.na(coa_grad_res))    

df_edu %>% glimpse()

```


# Part I: Measures of model fit

<br>

<span style="color:red"><b>/X<b></span>

#### 1. Define $R^2$ in words. Write out the mathematical formula for $R^2$ using both ways discussed in lecture.


- __YOUR ANSWER HERE__:  $R^2$ is the fraction of variance in Y explained by X (and is not already explained by sample mean, $\bar{Y}$). 

$R^2 = \frac{\text{variance in Y that is explained by X}}{\text{total variance in Y}} = \frac{ESS}{TSS}$

$R^2 = 1 - \frac{\text{variance in Y not explained by X}}{\text{total variance in Y}} = 1 - \frac{SSR}{TSS}$


<span style="color:red"><b>/X<b></span>  

#### 2. Using the code from below to guide you, write out the formula for TSS and explain what it means in words. Do the same for ESS and SSR. 

Consider the research question, what is the relationship between cost of attendance ($X$) and earnings  ($Y$) (2 years after graduation)?

Below we use the `lm()` function and create an object named `mod1` that contains results from the bivariate regression of the relationship between cost of attendance ($X$) and earnings 2 years after graduation ($Y$). We run the `anova()` function to get the values of ESS, SSR, TSS. 

- X= `coa_grad_res`
- Y= `earn_mdn_hi_2yr`

```{r}
mod1 <- lm(formula = earn_mdn_hi_2yr ~ coa_grad_res, data = df_edu)

summary(mod1)

anova(mod1)

```

Estimated sum of squares (ESS) = 323638309  
Sum of Squared Residuals (SSR) = 10633742116  
Total Sum of Squares (TSS) = ESS + SSR = 10,957,380,425


- __YOUR ANSWER HERE: TSS__: 

$TSS = \sum_{i=1}^{n} (Y_i-\bar{Y})^2$

Total sum of squares measures the total variance in Y, in terms of $\bar{Y}$

- __YOUR ANSWER HERE: ESS__:

$ESS = \sum_{i=1}^{n} (\hat{Y_i}-\bar{Y})^2$  

Explained sum of squares measures the amount of variation in Y explained by X.

- __YOUR ANSWER HERE: SSR__: 

$SSR = \sum_{i=1}^{n} (Y_i-\hat{Y})^2$   

The sum of squared residuals measures the amount of variation in Y not explained by X.


<span style="color:red"><b>/X<b></span>   

#### 3. Using the values for ESS, SSR, and TSS from above, calculate $R^2$ in both ways discussed in lecture (can do it by hand below or in a code chunk). Interpret the value of $R^2$ in words. 

- __YOUR ANSWER HERE__: The model explains 2.9% of the variation in Y (that is not already explained by sample mean, $\bar{Y}$)

```{r}
#ESS
anova(mod1)$"Sum Sq"[1]

#SSR
anova(mod1)$"Sum Sq"[2]

#TSS
anova(mod1)$"Sum Sq"[1] + anova(mod1)$"Sum Sq"[2]

#R2, ESS/TSS
anova(mod1)$"Sum Sq"[1] / (anova(mod1)$"Sum Sq"[1] + anova(mod1)$"Sum Sq"[2])

#R2, 1 - SSR/TSS
1 - anova(mod1)$"Sum Sq"[2] / (anova(mod1)$"Sum Sq"[1] + anova(mod1)$"Sum Sq"[2])
```



<span style="color:red"><b>/X<b></span> 

#### 4. Explain what sample standard deviation of a variable means in words and write out the formula. Explain what standard error of the regression (SER) means in words and write out the formula for SER (in terms of SSR). 

- __YOUR ANSWER HERE__: 

Sample standard deviation = The sample standard deviation of Y $\hat{\sigma}_Y$ measures the average distance between a random observation $Y_i$ and the sample mean $\bar{Y_i}$. 

$\hat{\sigma}_Y = \sqrt{\frac{\sum_{i=1}^{n} (Y_i-\bar{Y})^2}{n -1}}$  

Standard error of the regression (SER) = The standard error of the regression is an estimate of how far away, on average, an actual observed value of $Y_i$ is from the predicted value of $\hat{Y_i}$ of $Y_i$ for a random observation, $i$. 

$SER = \sqrt{\frac{\sum_{i=1}^{n} (Y_i-\hat{Y_i})^2}{n -2}} = \sqrt{\frac{\sum_{i=1}^{n} (\hat{\mu_i})^2}{n -2}}$  



<span style="color:red"><b>/X<b></span> 

#### 5. Run the analysis of the relationship between cost of attendance ($X$) and debt ($Y$)., do the following: run the regression in R (using `lm()` and `summary()`) and assign it to the object `mod2`; report the SER; and calculate the standard deviation of the dependent variable `sd()`, debt `debt_all_stgp_eval_mean`, in the regression model. 

- X= `coa_grad_res`
- Y= `debt_all_stgp_eval_mean`

```{r}
mod2 <- lm(formula = debt_all_stgp_eval_mean ~ coa_grad_res, data = df_edu)

summary(mod2)

#SER
summary(mod2)$sigma

#Standard deviation of debt
sd(df_edu$debt_all_stgp_eval_mean, na.rm = TRUE)
```


<span style="color:red"><b>/X<b></span> 

#### 6. Interpret the SER from the above model in words. Interpret sample standard deviation from above model in words. Does our model make our prediction substantially better? 


- __YOUR ANSWER HERE__: 

Interpretation of SER: On average, observed values of institution-level student debt ($Y_i$) are 9,931.327 dollars away from predicted values of institution-level student debt $\hat{Y_i}$.

Interpretation of sample standard deviation: On average, observations of $Y_i$ are 10,417.01 dollars away from the sample mean $\bar{Y_i}$ of Y.

- Yes, the model makes our prediction better. 


# Part II: Categorical X variables

<span style="color:red"><b>/X<b></span> 

#### 1. Explain what a reference group is in words.  

- __YOUR ANSWER HERE__:


<span style="color:red"><b>/X<b></span> 

#### 2. What is a factor variable and why is it important for running a regression?  

- __YOUR ANSWER HERE__:

<span style="color:red"><b>/X<b></span> 

#### 3. 

```{r}
df_edu %>% glimpse()
```



# Part III: Confidence interval about $\beta_k$

